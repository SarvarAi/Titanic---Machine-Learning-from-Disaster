{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "ecb9cdd0-be52-4cbd-96dd-477a489b6b32",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from matplotlib import pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0a422a4-cb5a-4f74-b9d1-f4f2d334f666",
   "metadata": {},
   "source": [
    "### 1. Loading the datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "id": "9f1b59d2-a653-40ef-83fa-590e6ac474b5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "train_data = pd.read_csv('data/preprocessed_train.csv')\n",
    "test_data = pd.read_csv('data/preprocessed_test.csv')\n",
    "\n",
    "raw_test_data = pd.read_csv('data/test.csv')\n",
    "test_data_passengers_id = raw_test_data['PassengerId']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "id": "df6502f5-d140-478d-812b-b2ecaa259d41",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "test_data = test_data.drop(['Unnamed: 0'], axis=1)\n",
    "train_data = train_data.drop(['Unnamed: 0'], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b22c41f0-8054-4ecc-abf6-24bc031903e0",
   "metadata": {
    "tags": []
   },
   "source": [
    "### 2. Splitting targets and features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "id": "74d24848-c744-408a-adb0-8430df471c55",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "targets_train = train_data.iloc[:, 0] \n",
    "features_train = train_data.iloc[:, 1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "id": "792ff38e-94c7-4a01-9743-7861b4f5d406",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "npTargets_train = np.array(targets_train)\n",
    "npFeatures_train = np.array(features_train)\n",
    "npTest_data = np.array(test_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8c0567c-5a01-4791-a2b4-abd0882dcb50",
   "metadata": {
    "tags": []
   },
   "source": [
    "### 3. Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "390cd29c-f297-4f93-b365-7ad3ae51e62f",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_26\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_89 (Dense)            (None, 8)                 72        \n",
      "                                                                 \n",
      " dense_90 (Dense)            (None, 1000)              9000      \n",
      "                                                                 \n",
      " dense_91 (Dense)            (None, 2000)              2002000   \n",
      "                                                                 \n",
      " dense_92 (Dense)            (None, 500)               1000500   \n",
      "                                                                 \n",
      " dense_93 (Dense)            (None, 1)                 501       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 3,012,073\n",
      "Trainable params: 3,012,073\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "LEARNING_RATE = 0.000001\n",
    "\n",
    "model = tf.keras.models.Sequential()\n",
    "\n",
    "model.add(tf.keras.layers.Dense(8, activation='relu'))\n",
    "model.add(tf.keras.layers.Dense(1000, activation='relu'))\n",
    "model.add(tf.keras.layers.Dense(2000, activation='relu'))\n",
    "model.add(tf.keras.layers.Dense(500, activation='relu'))\n",
    "model.add(tf.keras.layers.Dense(1, activation='sigmoid'))\n",
    "\n",
    "optimizer = tf.keras.optimizers.Adam(learning_rate=LEARNING_RATE)\n",
    "model.build((None, 8))  # Specify the input shape to build the model\n",
    "\n",
    "model.summary()\n",
    "\n",
    "model.compile(optimizer=optimizer, loss='binary_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "11e0fdd3-d170-49a3-bb34-6c63d4a2f0fc",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1000\n",
      "123/123 [==============================] - 2s 10ms/step - loss: 0.6919 - accuracy: 0.5245 - val_loss: 0.6900 - val_accuracy: 0.5588\n",
      "Epoch 2/1000\n",
      "123/123 [==============================] - 1s 7ms/step - loss: 0.6863 - accuracy: 0.6895 - val_loss: 0.6845 - val_accuracy: 0.7059\n",
      "Epoch 3/1000\n",
      "123/123 [==============================] - 1s 7ms/step - loss: 0.6812 - accuracy: 0.7288 - val_loss: 0.6797 - val_accuracy: 0.7500\n",
      "Epoch 4/1000\n",
      "123/123 [==============================] - 1s 7ms/step - loss: 0.6765 - accuracy: 0.7369 - val_loss: 0.6752 - val_accuracy: 0.7500\n",
      "Epoch 5/1000\n",
      "123/123 [==============================] - 1s 7ms/step - loss: 0.6720 - accuracy: 0.7271 - val_loss: 0.6707 - val_accuracy: 0.7500\n",
      "Epoch 6/1000\n",
      "123/123 [==============================] - 1s 7ms/step - loss: 0.6679 - accuracy: 0.7255 - val_loss: 0.6668 - val_accuracy: 0.7206\n",
      "Epoch 7/1000\n",
      "123/123 [==============================] - 1s 7ms/step - loss: 0.6640 - accuracy: 0.7190 - val_loss: 0.6629 - val_accuracy: 0.7206\n",
      "Epoch 8/1000\n",
      "123/123 [==============================] - 1s 8ms/step - loss: 0.6600 - accuracy: 0.7190 - val_loss: 0.6592 - val_accuracy: 0.7206\n",
      "Epoch 9/1000\n",
      "123/123 [==============================] - 1s 8ms/step - loss: 0.6563 - accuracy: 0.7222 - val_loss: 0.6554 - val_accuracy: 0.7206\n",
      "Epoch 10/1000\n",
      "123/123 [==============================] - 1s 7ms/step - loss: 0.6527 - accuracy: 0.7239 - val_loss: 0.6521 - val_accuracy: 0.7206\n",
      "Epoch 11/1000\n",
      "123/123 [==============================] - 1s 7ms/step - loss: 0.6492 - accuracy: 0.7271 - val_loss: 0.6488 - val_accuracy: 0.7206\n",
      "Epoch 12/1000\n",
      "123/123 [==============================] - 1s 8ms/step - loss: 0.6458 - accuracy: 0.7288 - val_loss: 0.6454 - val_accuracy: 0.7206\n",
      "Epoch 13/1000\n",
      "123/123 [==============================] - 1s 8ms/step - loss: 0.6424 - accuracy: 0.7288 - val_loss: 0.6424 - val_accuracy: 0.7500\n",
      "Epoch 14/1000\n",
      "123/123 [==============================] - 1s 7ms/step - loss: 0.6392 - accuracy: 0.7304 - val_loss: 0.6394 - val_accuracy: 0.7647\n",
      "Epoch 15/1000\n",
      "123/123 [==============================] - 1s 7ms/step - loss: 0.6360 - accuracy: 0.7320 - val_loss: 0.6361 - val_accuracy: 0.7794\n",
      "Epoch 16/1000\n",
      "123/123 [==============================] - 1s 8ms/step - loss: 0.6328 - accuracy: 0.7353 - val_loss: 0.6332 - val_accuracy: 0.7794\n",
      "Epoch 17/1000\n",
      "123/123 [==============================] - 1s 8ms/step - loss: 0.6298 - accuracy: 0.7337 - val_loss: 0.6305 - val_accuracy: 0.7647\n",
      "Epoch 18/1000\n",
      "123/123 [==============================] - 1s 7ms/step - loss: 0.6268 - accuracy: 0.7320 - val_loss: 0.6276 - val_accuracy: 0.7647\n",
      "Epoch 19/1000\n",
      "123/123 [==============================] - 1s 7ms/step - loss: 0.6238 - accuracy: 0.7353 - val_loss: 0.6250 - val_accuracy: 0.7794\n",
      "Epoch 20/1000\n",
      "123/123 [==============================] - 1s 7ms/step - loss: 0.6210 - accuracy: 0.7369 - val_loss: 0.6225 - val_accuracy: 0.7794\n",
      "Epoch 21/1000\n",
      "123/123 [==============================] - 1s 7ms/step - loss: 0.6181 - accuracy: 0.7435 - val_loss: 0.6199 - val_accuracy: 0.7647\n",
      "Epoch 22/1000\n",
      "123/123 [==============================] - 1s 7ms/step - loss: 0.6154 - accuracy: 0.7451 - val_loss: 0.6175 - val_accuracy: 0.7647\n",
      "Epoch 23/1000\n",
      "123/123 [==============================] - 1s 7ms/step - loss: 0.6127 - accuracy: 0.7451 - val_loss: 0.6152 - val_accuracy: 0.7500\n",
      "Epoch 24/1000\n",
      "123/123 [==============================] - 1s 7ms/step - loss: 0.6101 - accuracy: 0.7435 - val_loss: 0.6128 - val_accuracy: 0.7500\n",
      "Epoch 25/1000\n",
      "123/123 [==============================] - 1s 8ms/step - loss: 0.6073 - accuracy: 0.7467 - val_loss: 0.6106 - val_accuracy: 0.7500\n",
      "Epoch 26/1000\n",
      "123/123 [==============================] - 1s 7ms/step - loss: 0.6047 - accuracy: 0.7500 - val_loss: 0.6083 - val_accuracy: 0.7353\n",
      "Epoch 27/1000\n",
      "123/123 [==============================] - 1s 8ms/step - loss: 0.6023 - accuracy: 0.7516 - val_loss: 0.6062 - val_accuracy: 0.7353\n",
      "Epoch 28/1000\n",
      "123/123 [==============================] - 1s 7ms/step - loss: 0.5997 - accuracy: 0.7467 - val_loss: 0.6042 - val_accuracy: 0.7353\n",
      "Epoch 29/1000\n",
      "123/123 [==============================] - 1s 7ms/step - loss: 0.5973 - accuracy: 0.7451 - val_loss: 0.6022 - val_accuracy: 0.7353\n",
      "Epoch 30/1000\n",
      "123/123 [==============================] - 1s 7ms/step - loss: 0.5948 - accuracy: 0.7467 - val_loss: 0.6003 - val_accuracy: 0.7353\n",
      "Epoch 31/1000\n",
      "123/123 [==============================] - 1s 7ms/step - loss: 0.5925 - accuracy: 0.7484 - val_loss: 0.5984 - val_accuracy: 0.7353\n",
      "Epoch 32/1000\n",
      "123/123 [==============================] - 1s 7ms/step - loss: 0.5901 - accuracy: 0.7500 - val_loss: 0.5966 - val_accuracy: 0.7353\n",
      "Epoch 33/1000\n",
      "123/123 [==============================] - 1s 8ms/step - loss: 0.5878 - accuracy: 0.7549 - val_loss: 0.5947 - val_accuracy: 0.7353\n",
      "Epoch 34/1000\n",
      "123/123 [==============================] - 1s 7ms/step - loss: 0.5855 - accuracy: 0.7549 - val_loss: 0.5929 - val_accuracy: 0.7353\n",
      "Epoch 35/1000\n",
      "123/123 [==============================] - 1s 7ms/step - loss: 0.5832 - accuracy: 0.7549 - val_loss: 0.5911 - val_accuracy: 0.7353\n",
      "Epoch 36/1000\n",
      "123/123 [==============================] - 1s 7ms/step - loss: 0.5810 - accuracy: 0.7533 - val_loss: 0.5896 - val_accuracy: 0.7353\n",
      "Epoch 37/1000\n",
      "123/123 [==============================] - 1s 7ms/step - loss: 0.5790 - accuracy: 0.7549 - val_loss: 0.5879 - val_accuracy: 0.7206\n",
      "Epoch 38/1000\n",
      "123/123 [==============================] - 1s 7ms/step - loss: 0.5768 - accuracy: 0.7549 - val_loss: 0.5864 - val_accuracy: 0.7206\n",
      "Epoch 39/1000\n",
      "123/123 [==============================] - 1s 7ms/step - loss: 0.5750 - accuracy: 0.7565 - val_loss: 0.5849 - val_accuracy: 0.7206\n",
      "Epoch 40/1000\n",
      "123/123 [==============================] - 1s 7ms/step - loss: 0.5728 - accuracy: 0.7598 - val_loss: 0.5834 - val_accuracy: 0.7206\n",
      "Epoch 41/1000\n",
      "123/123 [==============================] - 1s 7ms/step - loss: 0.5708 - accuracy: 0.7582 - val_loss: 0.5821 - val_accuracy: 0.7206\n",
      "Epoch 42/1000\n",
      "123/123 [==============================] - 1s 7ms/step - loss: 0.5689 - accuracy: 0.7582 - val_loss: 0.5809 - val_accuracy: 0.7206\n",
      "Epoch 43/1000\n",
      "123/123 [==============================] - 1s 7ms/step - loss: 0.5670 - accuracy: 0.7598 - val_loss: 0.5794 - val_accuracy: 0.7206\n",
      "Epoch 44/1000\n",
      "123/123 [==============================] - 1s 7ms/step - loss: 0.5650 - accuracy: 0.7565 - val_loss: 0.5782 - val_accuracy: 0.7206\n",
      "Epoch 45/1000\n",
      "123/123 [==============================] - 1s 8ms/step - loss: 0.5631 - accuracy: 0.7565 - val_loss: 0.5770 - val_accuracy: 0.7206\n",
      "Epoch 46/1000\n",
      "123/123 [==============================] - 1s 7ms/step - loss: 0.5613 - accuracy: 0.7582 - val_loss: 0.5758 - val_accuracy: 0.7206\n",
      "Epoch 47/1000\n",
      "123/123 [==============================] - 1s 7ms/step - loss: 0.5595 - accuracy: 0.7565 - val_loss: 0.5746 - val_accuracy: 0.7206\n",
      "Epoch 48/1000\n",
      "123/123 [==============================] - 1s 7ms/step - loss: 0.5577 - accuracy: 0.7565 - val_loss: 0.5735 - val_accuracy: 0.7206\n",
      "Epoch 49/1000\n",
      "123/123 [==============================] - 1s 7ms/step - loss: 0.5560 - accuracy: 0.7549 - val_loss: 0.5724 - val_accuracy: 0.7206\n",
      "Epoch 50/1000\n",
      "123/123 [==============================] - 1s 7ms/step - loss: 0.5543 - accuracy: 0.7582 - val_loss: 0.5712 - val_accuracy: 0.7206\n",
      "Epoch 51/1000\n",
      "123/123 [==============================] - 1s 7ms/step - loss: 0.5526 - accuracy: 0.7582 - val_loss: 0.5702 - val_accuracy: 0.7206\n",
      "Epoch 52/1000\n",
      "123/123 [==============================] - 1s 7ms/step - loss: 0.5509 - accuracy: 0.7598 - val_loss: 0.5692 - val_accuracy: 0.7206\n",
      "Epoch 53/1000\n",
      "123/123 [==============================] - 1s 7ms/step - loss: 0.5492 - accuracy: 0.7598 - val_loss: 0.5684 - val_accuracy: 0.7206\n",
      "Epoch 54/1000\n",
      "123/123 [==============================] - 1s 7ms/step - loss: 0.5476 - accuracy: 0.7582 - val_loss: 0.5675 - val_accuracy: 0.7206\n",
      "Epoch 55/1000\n",
      "123/123 [==============================] - 1s 7ms/step - loss: 0.5462 - accuracy: 0.7582 - val_loss: 0.5665 - val_accuracy: 0.7059\n",
      "Epoch 56/1000\n",
      "123/123 [==============================] - 1s 7ms/step - loss: 0.5445 - accuracy: 0.7598 - val_loss: 0.5655 - val_accuracy: 0.7059\n",
      "Epoch 57/1000\n",
      "123/123 [==============================] - 1s 7ms/step - loss: 0.5431 - accuracy: 0.7598 - val_loss: 0.5646 - val_accuracy: 0.7059\n",
      "Epoch 58/1000\n",
      "123/123 [==============================] - 1s 7ms/step - loss: 0.5415 - accuracy: 0.7647 - val_loss: 0.5638 - val_accuracy: 0.7059\n",
      "Epoch 59/1000\n",
      "123/123 [==============================] - 1s 7ms/step - loss: 0.5399 - accuracy: 0.7582 - val_loss: 0.5629 - val_accuracy: 0.7059\n",
      "Epoch 60/1000\n",
      "123/123 [==============================] - 1s 7ms/step - loss: 0.5384 - accuracy: 0.7647 - val_loss: 0.5621 - val_accuracy: 0.7059\n",
      "Epoch 61/1000\n",
      "123/123 [==============================] - 1s 7ms/step - loss: 0.5370 - accuracy: 0.7647 - val_loss: 0.5614 - val_accuracy: 0.7059\n",
      "Epoch 62/1000\n",
      "123/123 [==============================] - 1s 8ms/step - loss: 0.5355 - accuracy: 0.7647 - val_loss: 0.5606 - val_accuracy: 0.7059\n",
      "Epoch 63/1000\n",
      "123/123 [==============================] - 1s 7ms/step - loss: 0.5343 - accuracy: 0.7647 - val_loss: 0.5599 - val_accuracy: 0.7059\n",
      "Epoch 64/1000\n",
      "123/123 [==============================] - 1s 8ms/step - loss: 0.5328 - accuracy: 0.7663 - val_loss: 0.5592 - val_accuracy: 0.7059\n",
      "Epoch 65/1000\n",
      "123/123 [==============================] - 1s 7ms/step - loss: 0.5315 - accuracy: 0.7680 - val_loss: 0.5585 - val_accuracy: 0.7059\n",
      "Epoch 66/1000\n",
      "123/123 [==============================] - 1s 7ms/step - loss: 0.5304 - accuracy: 0.7663 - val_loss: 0.5579 - val_accuracy: 0.7059\n",
      "Epoch 67/1000\n",
      "123/123 [==============================] - 1s 7ms/step - loss: 0.5290 - accuracy: 0.7712 - val_loss: 0.5573 - val_accuracy: 0.7059\n",
      "Epoch 68/1000\n",
      "123/123 [==============================] - 1s 7ms/step - loss: 0.5278 - accuracy: 0.7729 - val_loss: 0.5567 - val_accuracy: 0.7059\n",
      "Epoch 69/1000\n",
      "123/123 [==============================] - 1s 7ms/step - loss: 0.5265 - accuracy: 0.7712 - val_loss: 0.5561 - val_accuracy: 0.6912\n",
      "Epoch 70/1000\n",
      "123/123 [==============================] - 1s 7ms/step - loss: 0.5252 - accuracy: 0.7745 - val_loss: 0.5554 - val_accuracy: 0.6912\n",
      "Epoch 71/1000\n",
      "123/123 [==============================] - 1s 7ms/step - loss: 0.5241 - accuracy: 0.7761 - val_loss: 0.5548 - val_accuracy: 0.6912\n",
      "Epoch 72/1000\n",
      "123/123 [==============================] - 1s 8ms/step - loss: 0.5229 - accuracy: 0.7761 - val_loss: 0.5542 - val_accuracy: 0.6912\n",
      "Epoch 73/1000\n",
      "123/123 [==============================] - 1s 8ms/step - loss: 0.5218 - accuracy: 0.7794 - val_loss: 0.5537 - val_accuracy: 0.6912\n",
      "Epoch 74/1000\n",
      "123/123 [==============================] - 1s 7ms/step - loss: 0.5206 - accuracy: 0.7794 - val_loss: 0.5530 - val_accuracy: 0.6912\n",
      "Epoch 75/1000\n",
      "123/123 [==============================] - 1s 8ms/step - loss: 0.5197 - accuracy: 0.7794 - val_loss: 0.5524 - val_accuracy: 0.6912\n",
      "Epoch 76/1000\n",
      "123/123 [==============================] - 1s 7ms/step - loss: 0.5184 - accuracy: 0.7827 - val_loss: 0.5520 - val_accuracy: 0.6912\n",
      "Epoch 77/1000\n",
      "123/123 [==============================] - 1s 7ms/step - loss: 0.5174 - accuracy: 0.7827 - val_loss: 0.5514 - val_accuracy: 0.6912\n",
      "Epoch 78/1000\n",
      "123/123 [==============================] - 1s 7ms/step - loss: 0.5163 - accuracy: 0.7843 - val_loss: 0.5510 - val_accuracy: 0.6912\n",
      "Epoch 79/1000\n",
      "123/123 [==============================] - 1s 7ms/step - loss: 0.5152 - accuracy: 0.7843 - val_loss: 0.5506 - val_accuracy: 0.6912\n",
      "Epoch 80/1000\n",
      "123/123 [==============================] - 1s 7ms/step - loss: 0.5143 - accuracy: 0.7843 - val_loss: 0.5500 - val_accuracy: 0.6912\n",
      "Epoch 81/1000\n",
      "123/123 [==============================] - 1s 7ms/step - loss: 0.5133 - accuracy: 0.7859 - val_loss: 0.5495 - val_accuracy: 0.6912\n",
      "Epoch 82/1000\n",
      "123/123 [==============================] - 1s 7ms/step - loss: 0.5123 - accuracy: 0.7843 - val_loss: 0.5490 - val_accuracy: 0.6912\n",
      "Epoch 83/1000\n",
      "123/123 [==============================] - 1s 7ms/step - loss: 0.5114 - accuracy: 0.7859 - val_loss: 0.5486 - val_accuracy: 0.6912\n",
      "Epoch 84/1000\n",
      "123/123 [==============================] - 1s 7ms/step - loss: 0.5103 - accuracy: 0.7876 - val_loss: 0.5481 - val_accuracy: 0.6912\n",
      "Epoch 85/1000\n",
      "123/123 [==============================] - 1s 7ms/step - loss: 0.5095 - accuracy: 0.7827 - val_loss: 0.5478 - val_accuracy: 0.7059\n",
      "Epoch 86/1000\n",
      "123/123 [==============================] - 1s 7ms/step - loss: 0.5085 - accuracy: 0.7843 - val_loss: 0.5474 - val_accuracy: 0.6912\n",
      "Epoch 87/1000\n",
      "123/123 [==============================] - 1s 7ms/step - loss: 0.5075 - accuracy: 0.7876 - val_loss: 0.5471 - val_accuracy: 0.6912\n",
      "Epoch 88/1000\n",
      "123/123 [==============================] - 1s 7ms/step - loss: 0.5067 - accuracy: 0.7892 - val_loss: 0.5467 - val_accuracy: 0.6912\n",
      "Epoch 89/1000\n",
      "123/123 [==============================] - 1s 7ms/step - loss: 0.5058 - accuracy: 0.7859 - val_loss: 0.5464 - val_accuracy: 0.6912\n",
      "Epoch 90/1000\n",
      "123/123 [==============================] - 1s 7ms/step - loss: 0.5050 - accuracy: 0.7859 - val_loss: 0.5460 - val_accuracy: 0.6912\n",
      "Epoch 91/1000\n",
      "123/123 [==============================] - 1s 7ms/step - loss: 0.5041 - accuracy: 0.7876 - val_loss: 0.5456 - val_accuracy: 0.6912\n",
      "Epoch 92/1000\n",
      "123/123 [==============================] - 1s 8ms/step - loss: 0.5032 - accuracy: 0.7859 - val_loss: 0.5453 - val_accuracy: 0.6912\n",
      "Epoch 93/1000\n",
      "123/123 [==============================] - 1s 7ms/step - loss: 0.5026 - accuracy: 0.7876 - val_loss: 0.5450 - val_accuracy: 0.7059\n",
      "Epoch 94/1000\n",
      "123/123 [==============================] - 1s 7ms/step - loss: 0.5018 - accuracy: 0.7876 - val_loss: 0.5448 - val_accuracy: 0.6912\n",
      "Epoch 95/1000\n",
      "123/123 [==============================] - 1s 7ms/step - loss: 0.5009 - accuracy: 0.7876 - val_loss: 0.5442 - val_accuracy: 0.7059\n",
      "Epoch 96/1000\n",
      "123/123 [==============================] - 1s 7ms/step - loss: 0.5001 - accuracy: 0.7859 - val_loss: 0.5441 - val_accuracy: 0.7059\n",
      "Epoch 97/1000\n",
      "123/123 [==============================] - 1s 7ms/step - loss: 0.4994 - accuracy: 0.7876 - val_loss: 0.5438 - val_accuracy: 0.7059\n",
      "Epoch 98/1000\n",
      "123/123 [==============================] - 1s 7ms/step - loss: 0.4986 - accuracy: 0.7859 - val_loss: 0.5435 - val_accuracy: 0.7059\n",
      "Epoch 99/1000\n",
      "123/123 [==============================] - 1s 7ms/step - loss: 0.4979 - accuracy: 0.7892 - val_loss: 0.5432 - val_accuracy: 0.7206\n",
      "Epoch 100/1000\n",
      "123/123 [==============================] - 1s 7ms/step - loss: 0.4972 - accuracy: 0.7876 - val_loss: 0.5428 - val_accuracy: 0.7206\n",
      "Epoch 101/1000\n",
      "123/123 [==============================] - 1s 7ms/step - loss: 0.4965 - accuracy: 0.7892 - val_loss: 0.5426 - val_accuracy: 0.7206\n",
      "Epoch 102/1000\n",
      "123/123 [==============================] - 1s 7ms/step - loss: 0.4957 - accuracy: 0.7908 - val_loss: 0.5423 - val_accuracy: 0.7206\n",
      "Epoch 103/1000\n",
      "123/123 [==============================] - 1s 7ms/step - loss: 0.4950 - accuracy: 0.7892 - val_loss: 0.5420 - val_accuracy: 0.7206\n",
      "Epoch 104/1000\n",
      "123/123 [==============================] - 1s 7ms/step - loss: 0.4943 - accuracy: 0.7892 - val_loss: 0.5417 - val_accuracy: 0.7206\n",
      "Epoch 105/1000\n",
      "123/123 [==============================] - 1s 7ms/step - loss: 0.4937 - accuracy: 0.7908 - val_loss: 0.5412 - val_accuracy: 0.7206\n",
      "Epoch 106/1000\n",
      "123/123 [==============================] - 1s 7ms/step - loss: 0.4931 - accuracy: 0.7925 - val_loss: 0.5409 - val_accuracy: 0.7206\n",
      "Epoch 107/1000\n",
      "123/123 [==============================] - 1s 7ms/step - loss: 0.4924 - accuracy: 0.7908 - val_loss: 0.5409 - val_accuracy: 0.7206\n",
      "Epoch 108/1000\n",
      "123/123 [==============================] - 1s 7ms/step - loss: 0.4918 - accuracy: 0.7892 - val_loss: 0.5406 - val_accuracy: 0.7206\n",
      "Epoch 109/1000\n",
      "123/123 [==============================] - 1s 7ms/step - loss: 0.4911 - accuracy: 0.7908 - val_loss: 0.5402 - val_accuracy: 0.7206\n",
      "Epoch 110/1000\n",
      "123/123 [==============================] - 1s 7ms/step - loss: 0.4905 - accuracy: 0.7925 - val_loss: 0.5399 - val_accuracy: 0.7206\n",
      "Epoch 111/1000\n",
      "123/123 [==============================] - 1s 7ms/step - loss: 0.4900 - accuracy: 0.7908 - val_loss: 0.5395 - val_accuracy: 0.7059\n",
      "Epoch 112/1000\n",
      "123/123 [==============================] - 1s 7ms/step - loss: 0.4893 - accuracy: 0.7925 - val_loss: 0.5393 - val_accuracy: 0.7059\n",
      "Epoch 113/1000\n",
      "123/123 [==============================] - 1s 7ms/step - loss: 0.4888 - accuracy: 0.7908 - val_loss: 0.5390 - val_accuracy: 0.7059\n",
      "Epoch 114/1000\n",
      "123/123 [==============================] - 1s 7ms/step - loss: 0.4880 - accuracy: 0.7925 - val_loss: 0.5389 - val_accuracy: 0.7059\n",
      "Epoch 115/1000\n",
      "123/123 [==============================] - 1s 7ms/step - loss: 0.4877 - accuracy: 0.7925 - val_loss: 0.5386 - val_accuracy: 0.7059\n",
      "Epoch 116/1000\n",
      "123/123 [==============================] - 1s 8ms/step - loss: 0.4869 - accuracy: 0.7925 - val_loss: 0.5383 - val_accuracy: 0.7206\n",
      "Epoch 117/1000\n",
      "123/123 [==============================] - 1s 7ms/step - loss: 0.4865 - accuracy: 0.7941 - val_loss: 0.5381 - val_accuracy: 0.7059\n",
      "Epoch 118/1000\n",
      "123/123 [==============================] - 1s 7ms/step - loss: 0.4859 - accuracy: 0.7941 - val_loss: 0.5377 - val_accuracy: 0.7059\n",
      "Epoch 119/1000\n",
      "123/123 [==============================] - 1s 7ms/step - loss: 0.4853 - accuracy: 0.7925 - val_loss: 0.5377 - val_accuracy: 0.7206\n",
      "Epoch 120/1000\n",
      "123/123 [==============================] - 1s 7ms/step - loss: 0.4848 - accuracy: 0.7958 - val_loss: 0.5373 - val_accuracy: 0.7059\n",
      "Epoch 121/1000\n",
      "123/123 [==============================] - 1s 7ms/step - loss: 0.4845 - accuracy: 0.7958 - val_loss: 0.5371 - val_accuracy: 0.7059\n",
      "Epoch 122/1000\n",
      "123/123 [==============================] - 1s 7ms/step - loss: 0.4837 - accuracy: 0.7974 - val_loss: 0.5368 - val_accuracy: 0.7059\n",
      "Epoch 123/1000\n",
      "123/123 [==============================] - 1s 7ms/step - loss: 0.4832 - accuracy: 0.7974 - val_loss: 0.5365 - val_accuracy: 0.7059\n",
      "Epoch 124/1000\n",
      "123/123 [==============================] - 1s 7ms/step - loss: 0.4829 - accuracy: 0.7958 - val_loss: 0.5362 - val_accuracy: 0.7059\n",
      "Epoch 125/1000\n",
      "123/123 [==============================] - 1s 7ms/step - loss: 0.4821 - accuracy: 0.7958 - val_loss: 0.5360 - val_accuracy: 0.7059\n",
      "Epoch 126/1000\n",
      "123/123 [==============================] - 1s 7ms/step - loss: 0.4817 - accuracy: 0.7990 - val_loss: 0.5358 - val_accuracy: 0.7059\n",
      "Epoch 127/1000\n",
      "123/123 [==============================] - 1s 7ms/step - loss: 0.4812 - accuracy: 0.7990 - val_loss: 0.5355 - val_accuracy: 0.7059\n",
      "Epoch 128/1000\n",
      "123/123 [==============================] - 1s 7ms/step - loss: 0.4807 - accuracy: 0.7990 - val_loss: 0.5353 - val_accuracy: 0.7059\n",
      "Epoch 129/1000\n",
      "123/123 [==============================] - 1s 7ms/step - loss: 0.4801 - accuracy: 0.8007 - val_loss: 0.5350 - val_accuracy: 0.7059\n",
      "Epoch 130/1000\n",
      "123/123 [==============================] - 1s 7ms/step - loss: 0.4798 - accuracy: 0.7990 - val_loss: 0.5348 - val_accuracy: 0.7059\n",
      "Epoch 131/1000\n",
      "123/123 [==============================] - 1s 7ms/step - loss: 0.4793 - accuracy: 0.7990 - val_loss: 0.5346 - val_accuracy: 0.7059\n",
      "Epoch 132/1000\n",
      "123/123 [==============================] - 1s 7ms/step - loss: 0.4788 - accuracy: 0.7990 - val_loss: 0.5343 - val_accuracy: 0.7059\n",
      "Epoch 133/1000\n",
      "123/123 [==============================] - 1s 7ms/step - loss: 0.4784 - accuracy: 0.7958 - val_loss: 0.5341 - val_accuracy: 0.7059\n",
      "Epoch 134/1000\n",
      "123/123 [==============================] - 1s 8ms/step - loss: 0.4779 - accuracy: 0.7990 - val_loss: 0.5337 - val_accuracy: 0.7059\n",
      "Epoch 135/1000\n",
      "123/123 [==============================] - 1s 8ms/step - loss: 0.4775 - accuracy: 0.7990 - val_loss: 0.5336 - val_accuracy: 0.7059\n",
      "Epoch 136/1000\n",
      "123/123 [==============================] - 1s 7ms/step - loss: 0.4772 - accuracy: 0.7990 - val_loss: 0.5333 - val_accuracy: 0.7059\n",
      "Epoch 137/1000\n",
      "123/123 [==============================] - 1s 7ms/step - loss: 0.4765 - accuracy: 0.7974 - val_loss: 0.5331 - val_accuracy: 0.7059\n",
      "Epoch 138/1000\n",
      "123/123 [==============================] - 1s 7ms/step - loss: 0.4761 - accuracy: 0.7974 - val_loss: 0.5328 - val_accuracy: 0.7059\n",
      "Epoch 139/1000\n",
      "123/123 [==============================] - 1s 7ms/step - loss: 0.4757 - accuracy: 0.7990 - val_loss: 0.5328 - val_accuracy: 0.7059\n",
      "Epoch 140/1000\n",
      "123/123 [==============================] - 1s 7ms/step - loss: 0.4753 - accuracy: 0.7974 - val_loss: 0.5323 - val_accuracy: 0.7059\n",
      "Epoch 141/1000\n",
      "123/123 [==============================] - 1s 7ms/step - loss: 0.4748 - accuracy: 0.7974 - val_loss: 0.5320 - val_accuracy: 0.7059\n",
      "Epoch 142/1000\n",
      "123/123 [==============================] - 1s 7ms/step - loss: 0.4747 - accuracy: 0.7974 - val_loss: 0.5319 - val_accuracy: 0.7059\n",
      "Epoch 143/1000\n",
      "123/123 [==============================] - 1s 7ms/step - loss: 0.4741 - accuracy: 0.7974 - val_loss: 0.5317 - val_accuracy: 0.7059\n",
      "Epoch 144/1000\n",
      "123/123 [==============================] - 1s 7ms/step - loss: 0.4738 - accuracy: 0.7974 - val_loss: 0.5313 - val_accuracy: 0.7059\n",
      "Epoch 145/1000\n",
      "123/123 [==============================] - 1s 7ms/step - loss: 0.4733 - accuracy: 0.7958 - val_loss: 0.5312 - val_accuracy: 0.7059\n",
      "Epoch 146/1000\n",
      "123/123 [==============================] - 1s 7ms/step - loss: 0.4730 - accuracy: 0.7941 - val_loss: 0.5307 - val_accuracy: 0.7059\n",
      "Epoch 147/1000\n",
      "123/123 [==============================] - 1s 7ms/step - loss: 0.4726 - accuracy: 0.7958 - val_loss: 0.5306 - val_accuracy: 0.7059\n",
      "Epoch 148/1000\n",
      "123/123 [==============================] - 1s 7ms/step - loss: 0.4721 - accuracy: 0.7974 - val_loss: 0.5303 - val_accuracy: 0.7059\n",
      "Epoch 149/1000\n",
      "123/123 [==============================] - 1s 7ms/step - loss: 0.4718 - accuracy: 0.7958 - val_loss: 0.5303 - val_accuracy: 0.7059\n",
      "Epoch 150/1000\n",
      "123/123 [==============================] - 1s 7ms/step - loss: 0.4714 - accuracy: 0.7974 - val_loss: 0.5299 - val_accuracy: 0.7059\n",
      "Epoch 151/1000\n",
      "123/123 [==============================] - 1s 7ms/step - loss: 0.4710 - accuracy: 0.7974 - val_loss: 0.5298 - val_accuracy: 0.7059\n",
      "Epoch 152/1000\n",
      "123/123 [==============================] - 1s 7ms/step - loss: 0.4706 - accuracy: 0.7974 - val_loss: 0.5295 - val_accuracy: 0.7059\n",
      "Epoch 153/1000\n",
      "123/123 [==============================] - 1s 8ms/step - loss: 0.4702 - accuracy: 0.7974 - val_loss: 0.5294 - val_accuracy: 0.7059\n",
      "Epoch 154/1000\n",
      "123/123 [==============================] - 1s 7ms/step - loss: 0.4699 - accuracy: 0.7958 - val_loss: 0.5290 - val_accuracy: 0.7059\n",
      "Epoch 155/1000\n",
      "123/123 [==============================] - 1s 7ms/step - loss: 0.4695 - accuracy: 0.7941 - val_loss: 0.5288 - val_accuracy: 0.7059\n",
      "Epoch 156/1000\n",
      "123/123 [==============================] - 1s 7ms/step - loss: 0.4692 - accuracy: 0.7958 - val_loss: 0.5286 - val_accuracy: 0.7059\n",
      "Epoch 157/1000\n",
      "123/123 [==============================] - 1s 7ms/step - loss: 0.4688 - accuracy: 0.7974 - val_loss: 0.5283 - val_accuracy: 0.7059\n",
      "Epoch 158/1000\n",
      "123/123 [==============================] - 1s 7ms/step - loss: 0.4684 - accuracy: 0.7941 - val_loss: 0.5279 - val_accuracy: 0.7059\n",
      "Epoch 159/1000\n",
      "123/123 [==============================] - 1s 7ms/step - loss: 0.4681 - accuracy: 0.7958 - val_loss: 0.5279 - val_accuracy: 0.7059\n",
      "Epoch 160/1000\n",
      "123/123 [==============================] - 1s 7ms/step - loss: 0.4677 - accuracy: 0.7958 - val_loss: 0.5277 - val_accuracy: 0.7059\n",
      "Epoch 161/1000\n",
      "123/123 [==============================] - 1s 7ms/step - loss: 0.4674 - accuracy: 0.7958 - val_loss: 0.5275 - val_accuracy: 0.7059\n",
      "Epoch 162/1000\n",
      "123/123 [==============================] - 1s 8ms/step - loss: 0.4672 - accuracy: 0.7941 - val_loss: 0.5273 - val_accuracy: 0.7059\n",
      "Epoch 163/1000\n",
      "123/123 [==============================] - 1s 7ms/step - loss: 0.4668 - accuracy: 0.7958 - val_loss: 0.5273 - val_accuracy: 0.7059\n",
      "Epoch 164/1000\n",
      "123/123 [==============================] - 1s 7ms/step - loss: 0.4665 - accuracy: 0.7974 - val_loss: 0.5269 - val_accuracy: 0.7059\n",
      "Epoch 165/1000\n",
      "123/123 [==============================] - 1s 7ms/step - loss: 0.4661 - accuracy: 0.7974 - val_loss: 0.5265 - val_accuracy: 0.7059\n",
      "Epoch 166/1000\n",
      "123/123 [==============================] - 1s 7ms/step - loss: 0.4658 - accuracy: 0.7941 - val_loss: 0.5265 - val_accuracy: 0.7059\n",
      "Epoch 167/1000\n",
      "123/123 [==============================] - 1s 7ms/step - loss: 0.4655 - accuracy: 0.7974 - val_loss: 0.5263 - val_accuracy: 0.7059\n",
      "Epoch 168/1000\n",
      "123/123 [==============================] - 1s 7ms/step - loss: 0.4652 - accuracy: 0.7974 - val_loss: 0.5262 - val_accuracy: 0.7059\n",
      "Epoch 169/1000\n",
      "123/123 [==============================] - 1s 7ms/step - loss: 0.4649 - accuracy: 0.7974 - val_loss: 0.5259 - val_accuracy: 0.7059\n",
      "Epoch 170/1000\n",
      "123/123 [==============================] - 1s 7ms/step - loss: 0.4645 - accuracy: 0.7974 - val_loss: 0.5257 - val_accuracy: 0.7059\n",
      "Epoch 171/1000\n",
      "123/123 [==============================] - 1s 8ms/step - loss: 0.4643 - accuracy: 0.7974 - val_loss: 0.5255 - val_accuracy: 0.7059\n",
      "Epoch 172/1000\n",
      "123/123 [==============================] - 1s 7ms/step - loss: 0.4639 - accuracy: 0.7974 - val_loss: 0.5252 - val_accuracy: 0.7059\n",
      "Epoch 173/1000\n",
      "123/123 [==============================] - 1s 7ms/step - loss: 0.4637 - accuracy: 0.7974 - val_loss: 0.5250 - val_accuracy: 0.7059\n",
      "Epoch 174/1000\n",
      "123/123 [==============================] - 1s 7ms/step - loss: 0.4633 - accuracy: 0.7974 - val_loss: 0.5250 - val_accuracy: 0.7059\n",
      "Epoch 175/1000\n",
      "123/123 [==============================] - 1s 7ms/step - loss: 0.4630 - accuracy: 0.7974 - val_loss: 0.5246 - val_accuracy: 0.7059\n",
      "Epoch 176/1000\n",
      "123/123 [==============================] - 1s 7ms/step - loss: 0.4628 - accuracy: 0.7990 - val_loss: 0.5244 - val_accuracy: 0.7059\n",
      "Epoch 177/1000\n",
      "123/123 [==============================] - 1s 7ms/step - loss: 0.4624 - accuracy: 0.7990 - val_loss: 0.5242 - val_accuracy: 0.7059\n",
      "Epoch 178/1000\n",
      "123/123 [==============================] - 1s 7ms/step - loss: 0.4621 - accuracy: 0.7974 - val_loss: 0.5238 - val_accuracy: 0.7059\n",
      "Epoch 179/1000\n",
      "123/123 [==============================] - 1s 7ms/step - loss: 0.4618 - accuracy: 0.7990 - val_loss: 0.5238 - val_accuracy: 0.7059\n",
      "Epoch 180/1000\n",
      "123/123 [==============================] - 1s 7ms/step - loss: 0.4616 - accuracy: 0.7990 - val_loss: 0.5234 - val_accuracy: 0.7059\n",
      "Epoch 181/1000\n",
      "123/123 [==============================] - 1s 7ms/step - loss: 0.4614 - accuracy: 0.8007 - val_loss: 0.5232 - val_accuracy: 0.7059\n",
      "Epoch 182/1000\n",
      "123/123 [==============================] - 1s 7ms/step - loss: 0.4610 - accuracy: 0.7990 - val_loss: 0.5233 - val_accuracy: 0.7059\n",
      "Epoch 183/1000\n",
      "123/123 [==============================] - 1s 7ms/step - loss: 0.4609 - accuracy: 0.8023 - val_loss: 0.5229 - val_accuracy: 0.7059\n",
      "Epoch 184/1000\n",
      "123/123 [==============================] - 1s 7ms/step - loss: 0.4605 - accuracy: 0.7990 - val_loss: 0.5229 - val_accuracy: 0.7059\n",
      "Epoch 185/1000\n",
      "123/123 [==============================] - 1s 7ms/step - loss: 0.4601 - accuracy: 0.8023 - val_loss: 0.5226 - val_accuracy: 0.7059\n",
      "Epoch 186/1000\n",
      "123/123 [==============================] - 1s 7ms/step - loss: 0.4599 - accuracy: 0.8007 - val_loss: 0.5222 - val_accuracy: 0.7059\n",
      "Epoch 187/1000\n",
      "123/123 [==============================] - 1s 7ms/step - loss: 0.4598 - accuracy: 0.8023 - val_loss: 0.5223 - val_accuracy: 0.7059\n",
      "Epoch 188/1000\n",
      "123/123 [==============================] - 1s 7ms/step - loss: 0.4596 - accuracy: 0.7990 - val_loss: 0.5220 - val_accuracy: 0.7059\n",
      "Epoch 189/1000\n",
      "123/123 [==============================] - 1s 8ms/step - loss: 0.4595 - accuracy: 0.8039 - val_loss: 0.5218 - val_accuracy: 0.7059\n",
      "Epoch 190/1000\n",
      "123/123 [==============================] - 1s 8ms/step - loss: 0.4591 - accuracy: 0.8023 - val_loss: 0.5217 - val_accuracy: 0.7059\n",
      "Epoch 191/1000\n",
      "123/123 [==============================] - 1s 8ms/step - loss: 0.4588 - accuracy: 0.8039 - val_loss: 0.5213 - val_accuracy: 0.7059\n",
      "Epoch 192/1000\n",
      "123/123 [==============================] - 1s 7ms/step - loss: 0.4585 - accuracy: 0.8023 - val_loss: 0.5210 - val_accuracy: 0.7059\n",
      "Epoch 193/1000\n",
      "123/123 [==============================] - 1s 7ms/step - loss: 0.4583 - accuracy: 0.8023 - val_loss: 0.5207 - val_accuracy: 0.7059\n",
      "Epoch 194/1000\n",
      "123/123 [==============================] - 1s 8ms/step - loss: 0.4580 - accuracy: 0.8023 - val_loss: 0.5207 - val_accuracy: 0.7059\n",
      "Epoch 195/1000\n",
      "123/123 [==============================] - 1s 7ms/step - loss: 0.4578 - accuracy: 0.8039 - val_loss: 0.5205 - val_accuracy: 0.7059\n",
      "Epoch 196/1000\n",
      "123/123 [==============================] - 1s 8ms/step - loss: 0.4576 - accuracy: 0.8007 - val_loss: 0.5202 - val_accuracy: 0.7059\n",
      "Epoch 197/1000\n",
      "123/123 [==============================] - 1s 7ms/step - loss: 0.4574 - accuracy: 0.8023 - val_loss: 0.5199 - val_accuracy: 0.7059\n",
      "Epoch 198/1000\n",
      "123/123 [==============================] - 1s 7ms/step - loss: 0.4570 - accuracy: 0.8023 - val_loss: 0.5197 - val_accuracy: 0.7059\n",
      "Epoch 199/1000\n",
      "123/123 [==============================] - 1s 8ms/step - loss: 0.4567 - accuracy: 0.8023 - val_loss: 0.5198 - val_accuracy: 0.7059\n",
      "Epoch 200/1000\n",
      "123/123 [==============================] - 1s 7ms/step - loss: 0.4566 - accuracy: 0.8039 - val_loss: 0.5194 - val_accuracy: 0.7059\n",
      "Epoch 201/1000\n",
      "123/123 [==============================] - 1s 7ms/step - loss: 0.4564 - accuracy: 0.8039 - val_loss: 0.5192 - val_accuracy: 0.7059\n",
      "Epoch 202/1000\n",
      "123/123 [==============================] - 1s 7ms/step - loss: 0.4561 - accuracy: 0.8023 - val_loss: 0.5191 - val_accuracy: 0.7059\n",
      "Epoch 203/1000\n",
      "123/123 [==============================] - 1s 7ms/step - loss: 0.4559 - accuracy: 0.8039 - val_loss: 0.5191 - val_accuracy: 0.7059\n",
      "Epoch 204/1000\n",
      "123/123 [==============================] - 1s 7ms/step - loss: 0.4555 - accuracy: 0.8039 - val_loss: 0.5188 - val_accuracy: 0.7059\n",
      "Epoch 205/1000\n",
      "123/123 [==============================] - 1s 8ms/step - loss: 0.4553 - accuracy: 0.8023 - val_loss: 0.5186 - val_accuracy: 0.7059\n",
      "Epoch 206/1000\n",
      "123/123 [==============================] - 1s 7ms/step - loss: 0.4551 - accuracy: 0.8039 - val_loss: 0.5184 - val_accuracy: 0.7059\n",
      "Epoch 207/1000\n",
      "123/123 [==============================] - 1s 8ms/step - loss: 0.4549 - accuracy: 0.8023 - val_loss: 0.5182 - val_accuracy: 0.7059\n",
      "Epoch 208/1000\n",
      "123/123 [==============================] - 1s 7ms/step - loss: 0.4546 - accuracy: 0.8023 - val_loss: 0.5179 - val_accuracy: 0.7059\n",
      "Epoch 209/1000\n",
      "123/123 [==============================] - 1s 7ms/step - loss: 0.4545 - accuracy: 0.8039 - val_loss: 0.5178 - val_accuracy: 0.7059\n",
      "Epoch 210/1000\n",
      "123/123 [==============================] - 1s 7ms/step - loss: 0.4542 - accuracy: 0.8039 - val_loss: 0.5174 - val_accuracy: 0.7059\n",
      "Epoch 211/1000\n",
      "123/123 [==============================] - 1s 8ms/step - loss: 0.4541 - accuracy: 0.8039 - val_loss: 0.5174 - val_accuracy: 0.7059\n",
      "Epoch 212/1000\n",
      "123/123 [==============================] - 1s 7ms/step - loss: 0.4538 - accuracy: 0.8039 - val_loss: 0.5171 - val_accuracy: 0.7059\n",
      "Epoch 213/1000\n",
      "123/123 [==============================] - 1s 8ms/step - loss: 0.4536 - accuracy: 0.8056 - val_loss: 0.5169 - val_accuracy: 0.7059\n",
      "Epoch 214/1000\n",
      "123/123 [==============================] - 1s 7ms/step - loss: 0.4534 - accuracy: 0.8039 - val_loss: 0.5167 - val_accuracy: 0.7059\n",
      "Epoch 215/1000\n",
      "123/123 [==============================] - 1s 7ms/step - loss: 0.4531 - accuracy: 0.8039 - val_loss: 0.5163 - val_accuracy: 0.7206\n",
      "Epoch 216/1000\n",
      "123/123 [==============================] - 1s 7ms/step - loss: 0.4530 - accuracy: 0.8039 - val_loss: 0.5163 - val_accuracy: 0.7059\n",
      "Epoch 217/1000\n",
      "123/123 [==============================] - 1s 7ms/step - loss: 0.4527 - accuracy: 0.8023 - val_loss: 0.5160 - val_accuracy: 0.7206\n",
      "Epoch 218/1000\n",
      "123/123 [==============================] - 1s 7ms/step - loss: 0.4526 - accuracy: 0.8039 - val_loss: 0.5155 - val_accuracy: 0.7206\n",
      "Epoch 219/1000\n",
      "123/123 [==============================] - 1s 7ms/step - loss: 0.4524 - accuracy: 0.8023 - val_loss: 0.5159 - val_accuracy: 0.7059\n",
      "Epoch 220/1000\n",
      "123/123 [==============================] - 1s 7ms/step - loss: 0.4522 - accuracy: 0.8023 - val_loss: 0.5154 - val_accuracy: 0.7206\n",
      "Epoch 221/1000\n",
      "123/123 [==============================] - 1s 7ms/step - loss: 0.4520 - accuracy: 0.8023 - val_loss: 0.5152 - val_accuracy: 0.7206\n",
      "Epoch 222/1000\n",
      "123/123 [==============================] - 1s 7ms/step - loss: 0.4518 - accuracy: 0.8007 - val_loss: 0.5150 - val_accuracy: 0.7206\n",
      "Epoch 223/1000\n",
      "123/123 [==============================] - 1s 8ms/step - loss: 0.4517 - accuracy: 0.8039 - val_loss: 0.5148 - val_accuracy: 0.7206\n",
      "Epoch 224/1000\n",
      "123/123 [==============================] - 1s 8ms/step - loss: 0.4512 - accuracy: 0.8039 - val_loss: 0.5149 - val_accuracy: 0.7059\n",
      "Epoch 225/1000\n",
      "123/123 [==============================] - 1s 7ms/step - loss: 0.4512 - accuracy: 0.8039 - val_loss: 0.5144 - val_accuracy: 0.7059\n",
      "Epoch 226/1000\n",
      "123/123 [==============================] - 1s 8ms/step - loss: 0.4511 - accuracy: 0.8023 - val_loss: 0.5142 - val_accuracy: 0.7206\n",
      "Epoch 227/1000\n",
      "123/123 [==============================] - 1s 7ms/step - loss: 0.4506 - accuracy: 0.8023 - val_loss: 0.5140 - val_accuracy: 0.7206\n",
      "Epoch 228/1000\n",
      "123/123 [==============================] - 1s 7ms/step - loss: 0.4506 - accuracy: 0.8023 - val_loss: 0.5137 - val_accuracy: 0.7206\n",
      "Epoch 229/1000\n",
      "123/123 [==============================] - 1s 8ms/step - loss: 0.4503 - accuracy: 0.8023 - val_loss: 0.5138 - val_accuracy: 0.7059\n",
      "Epoch 230/1000\n",
      "123/123 [==============================] - 1s 7ms/step - loss: 0.4502 - accuracy: 0.8039 - val_loss: 0.5134 - val_accuracy: 0.7206\n",
      "Epoch 231/1000\n",
      "123/123 [==============================] - 1s 7ms/step - loss: 0.4502 - accuracy: 0.7990 - val_loss: 0.5135 - val_accuracy: 0.7059\n",
      "Epoch 232/1000\n",
      "123/123 [==============================] - 1s 7ms/step - loss: 0.4497 - accuracy: 0.8039 - val_loss: 0.5131 - val_accuracy: 0.7206\n",
      "Epoch 233/1000\n",
      "123/123 [==============================] - 1s 7ms/step - loss: 0.4496 - accuracy: 0.8039 - val_loss: 0.5130 - val_accuracy: 0.7206\n",
      "Epoch 234/1000\n",
      "123/123 [==============================] - 1s 7ms/step - loss: 0.4496 - accuracy: 0.8023 - val_loss: 0.5127 - val_accuracy: 0.7206\n",
      "Epoch 235/1000\n",
      "123/123 [==============================] - 1s 7ms/step - loss: 0.4493 - accuracy: 0.8039 - val_loss: 0.5123 - val_accuracy: 0.7206\n",
      "Epoch 236/1000\n",
      "123/123 [==============================] - 1s 7ms/step - loss: 0.4491 - accuracy: 0.8056 - val_loss: 0.5126 - val_accuracy: 0.7059\n",
      "Epoch 237/1000\n",
      "123/123 [==============================] - 1s 7ms/step - loss: 0.4489 - accuracy: 0.8023 - val_loss: 0.5122 - val_accuracy: 0.7206\n",
      "Epoch 238/1000\n",
      "123/123 [==============================] - 1s 7ms/step - loss: 0.4487 - accuracy: 0.8072 - val_loss: 0.5119 - val_accuracy: 0.7206\n",
      "Epoch 239/1000\n",
      "123/123 [==============================] - 1s 7ms/step - loss: 0.4486 - accuracy: 0.8056 - val_loss: 0.5120 - val_accuracy: 0.7206\n",
      "Epoch 240/1000\n",
      "123/123 [==============================] - 1s 7ms/step - loss: 0.4483 - accuracy: 0.8039 - val_loss: 0.5115 - val_accuracy: 0.7206\n",
      "Epoch 241/1000\n",
      "123/123 [==============================] - 1s 7ms/step - loss: 0.4483 - accuracy: 0.8007 - val_loss: 0.5110 - val_accuracy: 0.7206\n",
      "Epoch 242/1000\n",
      "123/123 [==============================] - 1s 8ms/step - loss: 0.4481 - accuracy: 0.8056 - val_loss: 0.5114 - val_accuracy: 0.7206\n",
      "Epoch 243/1000\n",
      "123/123 [==============================] - 1s 7ms/step - loss: 0.4479 - accuracy: 0.8023 - val_loss: 0.5109 - val_accuracy: 0.7206\n",
      "Epoch 244/1000\n",
      "123/123 [==============================] - 1s 7ms/step - loss: 0.4478 - accuracy: 0.8023 - val_loss: 0.5108 - val_accuracy: 0.7206\n",
      "Epoch 245/1000\n",
      "123/123 [==============================] - 1s 7ms/step - loss: 0.4477 - accuracy: 0.8056 - val_loss: 0.5109 - val_accuracy: 0.7206\n",
      "Epoch 246/1000\n",
      "123/123 [==============================] - 1s 7ms/step - loss: 0.4477 - accuracy: 0.8072 - val_loss: 0.5106 - val_accuracy: 0.7206\n",
      "Epoch 247/1000\n",
      "123/123 [==============================] - 1s 7ms/step - loss: 0.4472 - accuracy: 0.8007 - val_loss: 0.5105 - val_accuracy: 0.7206\n",
      "Epoch 248/1000\n",
      "123/123 [==============================] - 1s 7ms/step - loss: 0.4470 - accuracy: 0.8039 - val_loss: 0.5104 - val_accuracy: 0.7206\n",
      "Epoch 249/1000\n",
      "123/123 [==============================] - 1s 7ms/step - loss: 0.4467 - accuracy: 0.8039 - val_loss: 0.5099 - val_accuracy: 0.7206\n",
      "Epoch 250/1000\n",
      "123/123 [==============================] - 1s 7ms/step - loss: 0.4467 - accuracy: 0.8056 - val_loss: 0.5098 - val_accuracy: 0.7206\n",
      "Epoch 251/1000\n",
      "123/123 [==============================] - 1s 7ms/step - loss: 0.4466 - accuracy: 0.8007 - val_loss: 0.5096 - val_accuracy: 0.7206\n",
      "Epoch 252/1000\n",
      "123/123 [==============================] - 1s 8ms/step - loss: 0.4462 - accuracy: 0.8056 - val_loss: 0.5096 - val_accuracy: 0.7059\n",
      "Epoch 253/1000\n",
      "123/123 [==============================] - 1s 7ms/step - loss: 0.4462 - accuracy: 0.8039 - val_loss: 0.5094 - val_accuracy: 0.7059\n",
      "Epoch 254/1000\n",
      "123/123 [==============================] - 1s 7ms/step - loss: 0.4461 - accuracy: 0.8039 - val_loss: 0.5090 - val_accuracy: 0.7206\n",
      "Epoch 255/1000\n",
      "123/123 [==============================] - 1s 7ms/step - loss: 0.4458 - accuracy: 0.8039 - val_loss: 0.5088 - val_accuracy: 0.7206\n",
      "Epoch 256/1000\n",
      "123/123 [==============================] - 1s 7ms/step - loss: 0.4458 - accuracy: 0.8007 - val_loss: 0.5086 - val_accuracy: 0.7206\n",
      "Epoch 257/1000\n",
      "123/123 [==============================] - 1s 7ms/step - loss: 0.4453 - accuracy: 0.8039 - val_loss: 0.5090 - val_accuracy: 0.7059\n",
      "Epoch 258/1000\n",
      "123/123 [==============================] - 1s 7ms/step - loss: 0.4453 - accuracy: 0.8023 - val_loss: 0.5087 - val_accuracy: 0.7206\n",
      "Epoch 259/1000\n",
      "123/123 [==============================] - 1s 7ms/step - loss: 0.4453 - accuracy: 0.8007 - val_loss: 0.5086 - val_accuracy: 0.7059\n",
      "Epoch 260/1000\n",
      "123/123 [==============================] - 1s 8ms/step - loss: 0.4450 - accuracy: 0.8023 - val_loss: 0.5087 - val_accuracy: 0.7059\n",
      "Epoch 261/1000\n",
      "123/123 [==============================] - 1s 8ms/step - loss: 0.4449 - accuracy: 0.8039 - val_loss: 0.5083 - val_accuracy: 0.7059\n",
      "Epoch 262/1000\n",
      "123/123 [==============================] - 1s 7ms/step - loss: 0.4447 - accuracy: 0.8039 - val_loss: 0.5081 - val_accuracy: 0.7059\n",
      "Epoch 263/1000\n",
      "123/123 [==============================] - 1s 7ms/step - loss: 0.4446 - accuracy: 0.8023 - val_loss: 0.5081 - val_accuracy: 0.7059\n",
      "Epoch 264/1000\n",
      "123/123 [==============================] - 1s 7ms/step - loss: 0.4445 - accuracy: 0.8039 - val_loss: 0.5077 - val_accuracy: 0.7059\n",
      "Epoch 265/1000\n",
      "123/123 [==============================] - 1s 7ms/step - loss: 0.4443 - accuracy: 0.8023 - val_loss: 0.5074 - val_accuracy: 0.7206\n",
      "Epoch 266/1000\n",
      "123/123 [==============================] - 1s 8ms/step - loss: 0.4439 - accuracy: 0.8056 - val_loss: 0.5073 - val_accuracy: 0.7059\n",
      "Epoch 267/1000\n",
      "123/123 [==============================] - 1s 7ms/step - loss: 0.4438 - accuracy: 0.8039 - val_loss: 0.5072 - val_accuracy: 0.7059\n",
      "Epoch 268/1000\n",
      "123/123 [==============================] - 1s 8ms/step - loss: 0.4437 - accuracy: 0.8088 - val_loss: 0.5069 - val_accuracy: 0.7206\n",
      "Epoch 269/1000\n",
      "123/123 [==============================] - 1s 7ms/step - loss: 0.4436 - accuracy: 0.8056 - val_loss: 0.5069 - val_accuracy: 0.7206\n",
      "Epoch 270/1000\n",
      "123/123 [==============================] - 1s 8ms/step - loss: 0.4434 - accuracy: 0.8039 - val_loss: 0.5065 - val_accuracy: 0.7206\n",
      "Epoch 271/1000\n",
      "123/123 [==============================] - 1s 7ms/step - loss: 0.4434 - accuracy: 0.8056 - val_loss: 0.5065 - val_accuracy: 0.7206\n",
      "Epoch 272/1000\n",
      "123/123 [==============================] - 1s 7ms/step - loss: 0.4433 - accuracy: 0.8023 - val_loss: 0.5062 - val_accuracy: 0.7206\n",
      "Epoch 273/1000\n",
      "123/123 [==============================] - 1s 7ms/step - loss: 0.4430 - accuracy: 0.8039 - val_loss: 0.5061 - val_accuracy: 0.7206\n",
      "Epoch 274/1000\n",
      "123/123 [==============================] - 1s 8ms/step - loss: 0.4429 - accuracy: 0.8039 - val_loss: 0.5059 - val_accuracy: 0.7206\n",
      "Epoch 275/1000\n",
      "123/123 [==============================] - 1s 8ms/step - loss: 0.4428 - accuracy: 0.8039 - val_loss: 0.5056 - val_accuracy: 0.7206\n",
      "Epoch 276/1000\n",
      "123/123 [==============================] - 1s 7ms/step - loss: 0.4426 - accuracy: 0.8072 - val_loss: 0.5060 - val_accuracy: 0.7059\n",
      "Epoch 277/1000\n",
      "123/123 [==============================] - 1s 8ms/step - loss: 0.4424 - accuracy: 0.8088 - val_loss: 0.5053 - val_accuracy: 0.7206\n",
      "Epoch 278/1000\n",
      "123/123 [==============================] - 1s 7ms/step - loss: 0.4422 - accuracy: 0.8056 - val_loss: 0.5053 - val_accuracy: 0.7206\n",
      "Epoch 279/1000\n",
      "123/123 [==============================] - 1s 7ms/step - loss: 0.4421 - accuracy: 0.8056 - val_loss: 0.5051 - val_accuracy: 0.7206\n",
      "Epoch 280/1000\n",
      "123/123 [==============================] - 1s 7ms/step - loss: 0.4419 - accuracy: 0.8072 - val_loss: 0.5051 - val_accuracy: 0.7059\n",
      "Epoch 281/1000\n",
      "123/123 [==============================] - 1s 7ms/step - loss: 0.4421 - accuracy: 0.8056 - val_loss: 0.5049 - val_accuracy: 0.7059\n",
      "Epoch 282/1000\n",
      "123/123 [==============================] - 1s 7ms/step - loss: 0.4416 - accuracy: 0.8072 - val_loss: 0.5050 - val_accuracy: 0.7059\n",
      "Epoch 283/1000\n",
      "123/123 [==============================] - 1s 7ms/step - loss: 0.4416 - accuracy: 0.8072 - val_loss: 0.5047 - val_accuracy: 0.7059\n",
      "Epoch 284/1000\n",
      "123/123 [==============================] - 1s 8ms/step - loss: 0.4414 - accuracy: 0.8072 - val_loss: 0.5044 - val_accuracy: 0.7206\n",
      "Epoch 285/1000\n",
      "123/123 [==============================] - 1s 7ms/step - loss: 0.4412 - accuracy: 0.8056 - val_loss: 0.5044 - val_accuracy: 0.7206\n",
      "Epoch 286/1000\n",
      "123/123 [==============================] - 1s 7ms/step - loss: 0.4414 - accuracy: 0.8056 - val_loss: 0.5043 - val_accuracy: 0.7059\n",
      "Epoch 287/1000\n",
      "123/123 [==============================] - 1s 8ms/step - loss: 0.4410 - accuracy: 0.8056 - val_loss: 0.5041 - val_accuracy: 0.7059\n",
      "Epoch 288/1000\n",
      "123/123 [==============================] - 1s 7ms/step - loss: 0.4410 - accuracy: 0.8088 - val_loss: 0.5041 - val_accuracy: 0.7206\n",
      "Epoch 289/1000\n",
      "123/123 [==============================] - 1s 8ms/step - loss: 0.4407 - accuracy: 0.8105 - val_loss: 0.5039 - val_accuracy: 0.7206\n",
      "Epoch 290/1000\n",
      "123/123 [==============================] - 1s 7ms/step - loss: 0.4405 - accuracy: 0.8088 - val_loss: 0.5036 - val_accuracy: 0.7206\n",
      "Epoch 291/1000\n",
      "123/123 [==============================] - 1s 8ms/step - loss: 0.4407 - accuracy: 0.8088 - val_loss: 0.5035 - val_accuracy: 0.7353\n",
      "Epoch 292/1000\n",
      "123/123 [==============================] - 1s 7ms/step - loss: 0.4404 - accuracy: 0.8056 - val_loss: 0.5035 - val_accuracy: 0.7206\n",
      "Epoch 293/1000\n",
      "123/123 [==============================] - 1s 7ms/step - loss: 0.4402 - accuracy: 0.8072 - val_loss: 0.5030 - val_accuracy: 0.7353\n",
      "Epoch 294/1000\n",
      "123/123 [==============================] - 1s 7ms/step - loss: 0.4400 - accuracy: 0.8105 - val_loss: 0.5031 - val_accuracy: 0.7353\n",
      "Epoch 295/1000\n",
      "123/123 [==============================] - 1s 7ms/step - loss: 0.4400 - accuracy: 0.8072 - val_loss: 0.5028 - val_accuracy: 0.7353\n",
      "Epoch 296/1000\n",
      "123/123 [==============================] - 1s 7ms/step - loss: 0.4398 - accuracy: 0.8121 - val_loss: 0.5027 - val_accuracy: 0.7353\n",
      "Epoch 297/1000\n",
      "123/123 [==============================] - 1s 7ms/step - loss: 0.4398 - accuracy: 0.8056 - val_loss: 0.5025 - val_accuracy: 0.7353\n",
      "Epoch 298/1000\n",
      "123/123 [==============================] - 1s 7ms/step - loss: 0.4398 - accuracy: 0.8039 - val_loss: 0.5023 - val_accuracy: 0.7353\n",
      "Epoch 299/1000\n",
      "123/123 [==============================] - 1s 7ms/step - loss: 0.4393 - accuracy: 0.8088 - val_loss: 0.5024 - val_accuracy: 0.7353\n",
      "Epoch 300/1000\n",
      "123/123 [==============================] - 1s 7ms/step - loss: 0.4392 - accuracy: 0.8105 - val_loss: 0.5024 - val_accuracy: 0.7206\n",
      "Epoch 301/1000\n",
      "123/123 [==============================] - 1s 7ms/step - loss: 0.4392 - accuracy: 0.8056 - val_loss: 0.5021 - val_accuracy: 0.7353\n",
      "Epoch 302/1000\n",
      "123/123 [==============================] - 1s 7ms/step - loss: 0.4391 - accuracy: 0.8105 - val_loss: 0.5021 - val_accuracy: 0.7206\n",
      "Epoch 303/1000\n",
      "123/123 [==============================] - 1s 7ms/step - loss: 0.4391 - accuracy: 0.8072 - val_loss: 0.5018 - val_accuracy: 0.7353\n",
      "Epoch 304/1000\n",
      "123/123 [==============================] - 1s 7ms/step - loss: 0.4387 - accuracy: 0.8039 - val_loss: 0.5016 - val_accuracy: 0.7353\n",
      "Epoch 305/1000\n",
      "123/123 [==============================] - 1s 7ms/step - loss: 0.4387 - accuracy: 0.8023 - val_loss: 0.5017 - val_accuracy: 0.7206\n",
      "Epoch 306/1000\n",
      "123/123 [==============================] - 1s 7ms/step - loss: 0.4389 - accuracy: 0.8105 - val_loss: 0.5014 - val_accuracy: 0.7353\n",
      "Epoch 307/1000\n",
      "123/123 [==============================] - 1s 7ms/step - loss: 0.4384 - accuracy: 0.8088 - val_loss: 0.5010 - val_accuracy: 0.7353\n",
      "Epoch 308/1000\n",
      "123/123 [==============================] - 1s 7ms/step - loss: 0.4383 - accuracy: 0.8023 - val_loss: 0.5010 - val_accuracy: 0.7353\n",
      "Epoch 309/1000\n",
      "123/123 [==============================] - 1s 8ms/step - loss: 0.4382 - accuracy: 0.8088 - val_loss: 0.5009 - val_accuracy: 0.7206\n",
      "Epoch 310/1000\n",
      "123/123 [==============================] - 1s 7ms/step - loss: 0.4381 - accuracy: 0.8088 - val_loss: 0.5011 - val_accuracy: 0.7206\n",
      "Epoch 311/1000\n",
      "123/123 [==============================] - 1s 7ms/step - loss: 0.4378 - accuracy: 0.8072 - val_loss: 0.5004 - val_accuracy: 0.7353\n",
      "Epoch 312/1000\n",
      "123/123 [==============================] - 1s 7ms/step - loss: 0.4378 - accuracy: 0.8056 - val_loss: 0.5003 - val_accuracy: 0.7353\n",
      "Epoch 313/1000\n",
      "123/123 [==============================] - 1s 8ms/step - loss: 0.4377 - accuracy: 0.8072 - val_loss: 0.5001 - val_accuracy: 0.7353\n",
      "Epoch 314/1000\n",
      "123/123 [==============================] - 1s 7ms/step - loss: 0.4377 - accuracy: 0.8023 - val_loss: 0.5001 - val_accuracy: 0.7353\n",
      "Epoch 315/1000\n",
      "123/123 [==============================] - 1s 8ms/step - loss: 0.4375 - accuracy: 0.8088 - val_loss: 0.5004 - val_accuracy: 0.7206\n",
      "Epoch 316/1000\n",
      "123/123 [==============================] - 1s 7ms/step - loss: 0.4373 - accuracy: 0.8072 - val_loss: 0.5000 - val_accuracy: 0.7353\n",
      "Epoch 317/1000\n",
      "123/123 [==============================] - 1s 8ms/step - loss: 0.4372 - accuracy: 0.8056 - val_loss: 0.5004 - val_accuracy: 0.7206\n",
      "Epoch 318/1000\n",
      "123/123 [==============================] - 1s 8ms/step - loss: 0.4371 - accuracy: 0.8056 - val_loss: 0.5000 - val_accuracy: 0.7206\n",
      "Epoch 319/1000\n",
      "123/123 [==============================] - 1s 7ms/step - loss: 0.4369 - accuracy: 0.8072 - val_loss: 0.4997 - val_accuracy: 0.7206\n",
      "Epoch 320/1000\n",
      "123/123 [==============================] - 1s 8ms/step - loss: 0.4369 - accuracy: 0.8105 - val_loss: 0.4996 - val_accuracy: 0.7206\n",
      "Epoch 321/1000\n",
      "123/123 [==============================] - 1s 7ms/step - loss: 0.4369 - accuracy: 0.8039 - val_loss: 0.4993 - val_accuracy: 0.7206\n",
      "Epoch 322/1000\n",
      "123/123 [==============================] - 1s 7ms/step - loss: 0.4367 - accuracy: 0.8072 - val_loss: 0.4999 - val_accuracy: 0.7206\n",
      "Epoch 323/1000\n",
      "123/123 [==============================] - 1s 7ms/step - loss: 0.4366 - accuracy: 0.8105 - val_loss: 0.4992 - val_accuracy: 0.7206\n",
      "Epoch 324/1000\n",
      "123/123 [==============================] - 1s 7ms/step - loss: 0.4365 - accuracy: 0.8039 - val_loss: 0.4991 - val_accuracy: 0.7206\n",
      "Epoch 325/1000\n",
      "123/123 [==============================] - 1s 7ms/step - loss: 0.4362 - accuracy: 0.8088 - val_loss: 0.4993 - val_accuracy: 0.7206\n",
      "Epoch 326/1000\n",
      "123/123 [==============================] - 1s 7ms/step - loss: 0.4362 - accuracy: 0.8072 - val_loss: 0.4985 - val_accuracy: 0.7353\n",
      "Epoch 327/1000\n",
      "123/123 [==============================] - 1s 7ms/step - loss: 0.4361 - accuracy: 0.8056 - val_loss: 0.4987 - val_accuracy: 0.7353\n",
      "Epoch 328/1000\n",
      "123/123 [==============================] - 1s 7ms/step - loss: 0.4364 - accuracy: 0.8121 - val_loss: 0.4988 - val_accuracy: 0.7353\n",
      "Epoch 329/1000\n",
      "123/123 [==============================] - 1s 8ms/step - loss: 0.4358 - accuracy: 0.8039 - val_loss: 0.4981 - val_accuracy: 0.7353\n",
      "Epoch 330/1000\n",
      "123/123 [==============================] - 1s 7ms/step - loss: 0.4356 - accuracy: 0.8072 - val_loss: 0.4983 - val_accuracy: 0.7353\n",
      "Epoch 331/1000\n",
      "123/123 [==============================] - 1s 7ms/step - loss: 0.4356 - accuracy: 0.8056 - val_loss: 0.4982 - val_accuracy: 0.7353\n",
      "Epoch 332/1000\n",
      "123/123 [==============================] - 1s 8ms/step - loss: 0.4357 - accuracy: 0.8023 - val_loss: 0.4977 - val_accuracy: 0.7353\n",
      "Epoch 333/1000\n",
      "123/123 [==============================] - 1s 7ms/step - loss: 0.4354 - accuracy: 0.8088 - val_loss: 0.4981 - val_accuracy: 0.7353\n",
      "Epoch 334/1000\n",
      "123/123 [==============================] - 1s 8ms/step - loss: 0.4352 - accuracy: 0.8039 - val_loss: 0.4971 - val_accuracy: 0.7353\n",
      "Epoch 335/1000\n",
      "123/123 [==============================] - 1s 7ms/step - loss: 0.4352 - accuracy: 0.8056 - val_loss: 0.4976 - val_accuracy: 0.7353\n",
      "Epoch 336/1000\n",
      "123/123 [==============================] - 1s 7ms/step - loss: 0.4349 - accuracy: 0.8056 - val_loss: 0.4973 - val_accuracy: 0.7353\n",
      "Epoch 337/1000\n",
      "123/123 [==============================] - 1s 8ms/step - loss: 0.4348 - accuracy: 0.8072 - val_loss: 0.4968 - val_accuracy: 0.7500\n",
      "Epoch 338/1000\n",
      "123/123 [==============================] - 1s 8ms/step - loss: 0.4350 - accuracy: 0.8072 - val_loss: 0.4971 - val_accuracy: 0.7353\n",
      "Epoch 339/1000\n",
      "123/123 [==============================] - 1s 8ms/step - loss: 0.4346 - accuracy: 0.8056 - val_loss: 0.4966 - val_accuracy: 0.7500\n",
      "Epoch 340/1000\n",
      "123/123 [==============================] - 1s 8ms/step - loss: 0.4346 - accuracy: 0.8072 - val_loss: 0.4968 - val_accuracy: 0.7500\n",
      "Epoch 341/1000\n",
      "123/123 [==============================] - 1s 8ms/step - loss: 0.4345 - accuracy: 0.8039 - val_loss: 0.4967 - val_accuracy: 0.7500\n",
      "Epoch 342/1000\n",
      "123/123 [==============================] - 1s 7ms/step - loss: 0.4343 - accuracy: 0.8056 - val_loss: 0.4963 - val_accuracy: 0.7500\n",
      "Epoch 343/1000\n",
      "123/123 [==============================] - 1s 7ms/step - loss: 0.4341 - accuracy: 0.8056 - val_loss: 0.4966 - val_accuracy: 0.7500\n",
      "Epoch 344/1000\n",
      "123/123 [==============================] - 1s 7ms/step - loss: 0.4342 - accuracy: 0.8088 - val_loss: 0.4965 - val_accuracy: 0.7500\n",
      "Epoch 345/1000\n",
      "123/123 [==============================] - 1s 7ms/step - loss: 0.4340 - accuracy: 0.8056 - val_loss: 0.4965 - val_accuracy: 0.7500\n",
      "Epoch 346/1000\n",
      "123/123 [==============================] - 1s 8ms/step - loss: 0.4337 - accuracy: 0.8072 - val_loss: 0.4962 - val_accuracy: 0.7500\n",
      "Epoch 347/1000\n",
      "123/123 [==============================] - 1s 8ms/step - loss: 0.4339 - accuracy: 0.8105 - val_loss: 0.4962 - val_accuracy: 0.7500\n",
      "Epoch 348/1000\n",
      "123/123 [==============================] - 1s 9ms/step - loss: 0.4336 - accuracy: 0.8007 - val_loss: 0.4957 - val_accuracy: 0.7500\n",
      "Epoch 349/1000\n",
      "123/123 [==============================] - 1s 8ms/step - loss: 0.4335 - accuracy: 0.8072 - val_loss: 0.4959 - val_accuracy: 0.7500\n",
      "Epoch 350/1000\n",
      "123/123 [==============================] - 1s 7ms/step - loss: 0.4335 - accuracy: 0.8056 - val_loss: 0.4960 - val_accuracy: 0.7500\n",
      "Epoch 351/1000\n",
      "123/123 [==============================] - 1s 7ms/step - loss: 0.4334 - accuracy: 0.8088 - val_loss: 0.4959 - val_accuracy: 0.7500\n",
      "Epoch 352/1000\n",
      "123/123 [==============================] - 1s 7ms/step - loss: 0.4333 - accuracy: 0.8056 - val_loss: 0.4958 - val_accuracy: 0.7500\n",
      "Epoch 353/1000\n",
      "123/123 [==============================] - 1s 7ms/step - loss: 0.4333 - accuracy: 0.8088 - val_loss: 0.4957 - val_accuracy: 0.7500\n",
      "Epoch 354/1000\n",
      "123/123 [==============================] - 1s 7ms/step - loss: 0.4329 - accuracy: 0.8056 - val_loss: 0.4956 - val_accuracy: 0.7500\n",
      "Epoch 355/1000\n",
      "123/123 [==============================] - 1s 7ms/step - loss: 0.4329 - accuracy: 0.8072 - val_loss: 0.4951 - val_accuracy: 0.7500\n",
      "Epoch 356/1000\n",
      "123/123 [==============================] - 1s 7ms/step - loss: 0.4329 - accuracy: 0.8039 - val_loss: 0.4950 - val_accuracy: 0.7500\n",
      "Epoch 357/1000\n",
      "123/123 [==============================] - 1s 7ms/step - loss: 0.4327 - accuracy: 0.8056 - val_loss: 0.4951 - val_accuracy: 0.7500\n",
      "Epoch 358/1000\n",
      "123/123 [==============================] - 1s 7ms/step - loss: 0.4325 - accuracy: 0.8072 - val_loss: 0.4949 - val_accuracy: 0.7500\n",
      "Epoch 359/1000\n",
      "123/123 [==============================] - 1s 7ms/step - loss: 0.4327 - accuracy: 0.8056 - val_loss: 0.4950 - val_accuracy: 0.7500\n",
      "Epoch 360/1000\n",
      "123/123 [==============================] - 1s 7ms/step - loss: 0.4323 - accuracy: 0.8039 - val_loss: 0.4947 - val_accuracy: 0.7500\n",
      "Epoch 361/1000\n",
      "123/123 [==============================] - 1s 7ms/step - loss: 0.4324 - accuracy: 0.8056 - val_loss: 0.4947 - val_accuracy: 0.7500\n",
      "Epoch 362/1000\n",
      "123/123 [==============================] - 1s 7ms/step - loss: 0.4321 - accuracy: 0.8056 - val_loss: 0.4947 - val_accuracy: 0.7500\n",
      "Epoch 363/1000\n",
      "123/123 [==============================] - 1s 7ms/step - loss: 0.4322 - accuracy: 0.8056 - val_loss: 0.4944 - val_accuracy: 0.7500\n",
      "Epoch 364/1000\n",
      "123/123 [==============================] - 1s 7ms/step - loss: 0.4322 - accuracy: 0.8007 - val_loss: 0.4942 - val_accuracy: 0.7500\n",
      "Epoch 365/1000\n",
      "123/123 [==============================] - 1s 8ms/step - loss: 0.4319 - accuracy: 0.8072 - val_loss: 0.4943 - val_accuracy: 0.7500\n",
      "Epoch 366/1000\n",
      "123/123 [==============================] - 1s 7ms/step - loss: 0.4319 - accuracy: 0.8056 - val_loss: 0.4940 - val_accuracy: 0.7500\n",
      "Epoch 367/1000\n",
      "123/123 [==============================] - 1s 7ms/step - loss: 0.4319 - accuracy: 0.8039 - val_loss: 0.4936 - val_accuracy: 0.7500\n",
      "Epoch 368/1000\n",
      "123/123 [==============================] - 1s 7ms/step - loss: 0.4316 - accuracy: 0.8072 - val_loss: 0.4939 - val_accuracy: 0.7500\n",
      "Epoch 369/1000\n",
      "123/123 [==============================] - 1s 7ms/step - loss: 0.4316 - accuracy: 0.8023 - val_loss: 0.4936 - val_accuracy: 0.7500\n",
      "Epoch 370/1000\n",
      "123/123 [==============================] - 1s 7ms/step - loss: 0.4314 - accuracy: 0.8023 - val_loss: 0.4932 - val_accuracy: 0.7500\n",
      "Epoch 371/1000\n",
      "123/123 [==============================] - 1s 7ms/step - loss: 0.4312 - accuracy: 0.8039 - val_loss: 0.4937 - val_accuracy: 0.7500\n",
      "Epoch 372/1000\n",
      "123/123 [==============================] - 1s 7ms/step - loss: 0.4312 - accuracy: 0.8056 - val_loss: 0.4940 - val_accuracy: 0.7647\n",
      "Epoch 373/1000\n",
      "123/123 [==============================] - 1s 7ms/step - loss: 0.4309 - accuracy: 0.8072 - val_loss: 0.4938 - val_accuracy: 0.7647\n",
      "Epoch 374/1000\n",
      "123/123 [==============================] - 1s 7ms/step - loss: 0.4311 - accuracy: 0.8056 - val_loss: 0.4932 - val_accuracy: 0.7500\n",
      "Epoch 375/1000\n",
      "123/123 [==============================] - 1s 7ms/step - loss: 0.4308 - accuracy: 0.8056 - val_loss: 0.4930 - val_accuracy: 0.7500\n",
      "Epoch 376/1000\n",
      "123/123 [==============================] - 1s 7ms/step - loss: 0.4308 - accuracy: 0.8039 - val_loss: 0.4932 - val_accuracy: 0.7500\n",
      "Epoch 377/1000\n",
      "123/123 [==============================] - 1s 7ms/step - loss: 0.4307 - accuracy: 0.8056 - val_loss: 0.4929 - val_accuracy: 0.7647\n",
      "Epoch 378/1000\n",
      "123/123 [==============================] - 1s 7ms/step - loss: 0.4308 - accuracy: 0.8039 - val_loss: 0.4928 - val_accuracy: 0.7500\n",
      "Epoch 379/1000\n",
      "123/123 [==============================] - 1s 7ms/step - loss: 0.4304 - accuracy: 0.8056 - val_loss: 0.4930 - val_accuracy: 0.7647\n",
      "Epoch 380/1000\n",
      "123/123 [==============================] - 1s 7ms/step - loss: 0.4303 - accuracy: 0.8072 - val_loss: 0.4929 - val_accuracy: 0.7647\n",
      "Epoch 381/1000\n",
      "123/123 [==============================] - 1s 8ms/step - loss: 0.4305 - accuracy: 0.8056 - val_loss: 0.4928 - val_accuracy: 0.7647\n",
      "Epoch 382/1000\n",
      "123/123 [==============================] - 1s 8ms/step - loss: 0.4302 - accuracy: 0.8072 - val_loss: 0.4926 - val_accuracy: 0.7647\n",
      "Epoch 383/1000\n",
      "123/123 [==============================] - 1s 8ms/step - loss: 0.4301 - accuracy: 0.8056 - val_loss: 0.4925 - val_accuracy: 0.7647\n",
      "Epoch 384/1000\n",
      "123/123 [==============================] - 1s 7ms/step - loss: 0.4300 - accuracy: 0.8039 - val_loss: 0.4923 - val_accuracy: 0.7647\n",
      "Epoch 385/1000\n",
      "123/123 [==============================] - 1s 7ms/step - loss: 0.4299 - accuracy: 0.8039 - val_loss: 0.4923 - val_accuracy: 0.7647\n",
      "Epoch 386/1000\n",
      "123/123 [==============================] - 1s 7ms/step - loss: 0.4298 - accuracy: 0.8039 - val_loss: 0.4921 - val_accuracy: 0.7647\n",
      "Epoch 387/1000\n",
      "123/123 [==============================] - 1s 7ms/step - loss: 0.4296 - accuracy: 0.8056 - val_loss: 0.4920 - val_accuracy: 0.7647\n",
      "Epoch 388/1000\n",
      "123/123 [==============================] - 1s 7ms/step - loss: 0.4298 - accuracy: 0.8039 - val_loss: 0.4915 - val_accuracy: 0.7500\n",
      "Epoch 389/1000\n",
      "123/123 [==============================] - 1s 7ms/step - loss: 0.4296 - accuracy: 0.8056 - val_loss: 0.4918 - val_accuracy: 0.7647\n",
      "Epoch 390/1000\n",
      "123/123 [==============================] - 1s 7ms/step - loss: 0.4293 - accuracy: 0.8039 - val_loss: 0.4913 - val_accuracy: 0.7500\n",
      "Epoch 391/1000\n",
      "123/123 [==============================] - 1s 7ms/step - loss: 0.4293 - accuracy: 0.8039 - val_loss: 0.4911 - val_accuracy: 0.7500\n",
      "Epoch 392/1000\n",
      "123/123 [==============================] - 1s 7ms/step - loss: 0.4292 - accuracy: 0.8056 - val_loss: 0.4913 - val_accuracy: 0.7647\n",
      "Epoch 393/1000\n",
      "123/123 [==============================] - 1s 7ms/step - loss: 0.4293 - accuracy: 0.8056 - val_loss: 0.4914 - val_accuracy: 0.7647\n",
      "Epoch 394/1000\n",
      "123/123 [==============================] - 1s 7ms/step - loss: 0.4290 - accuracy: 0.8023 - val_loss: 0.4909 - val_accuracy: 0.7647\n",
      "Epoch 395/1000\n",
      "123/123 [==============================] - 1s 7ms/step - loss: 0.4288 - accuracy: 0.8056 - val_loss: 0.4908 - val_accuracy: 0.7647\n",
      "Epoch 396/1000\n",
      "123/123 [==============================] - 1s 7ms/step - loss: 0.4290 - accuracy: 0.8056 - val_loss: 0.4909 - val_accuracy: 0.7647\n",
      "Epoch 397/1000\n",
      "123/123 [==============================] - 1s 7ms/step - loss: 0.4287 - accuracy: 0.8039 - val_loss: 0.4907 - val_accuracy: 0.7647\n",
      "Epoch 398/1000\n",
      "123/123 [==============================] - 1s 7ms/step - loss: 0.4286 - accuracy: 0.8039 - val_loss: 0.4904 - val_accuracy: 0.7647\n",
      "Epoch 399/1000\n",
      "123/123 [==============================] - 1s 7ms/step - loss: 0.4286 - accuracy: 0.8056 - val_loss: 0.4907 - val_accuracy: 0.7647\n",
      "Epoch 400/1000\n",
      "123/123 [==============================] - 1s 7ms/step - loss: 0.4286 - accuracy: 0.8039 - val_loss: 0.4905 - val_accuracy: 0.7647\n",
      "Epoch 401/1000\n",
      "123/123 [==============================] - 1s 8ms/step - loss: 0.4285 - accuracy: 0.8056 - val_loss: 0.4906 - val_accuracy: 0.7647\n",
      "Epoch 402/1000\n",
      "123/123 [==============================] - 1s 7ms/step - loss: 0.4283 - accuracy: 0.8039 - val_loss: 0.4906 - val_accuracy: 0.7647\n",
      "Epoch 403/1000\n",
      "123/123 [==============================] - 1s 7ms/step - loss: 0.4283 - accuracy: 0.8039 - val_loss: 0.4904 - val_accuracy: 0.7647\n",
      "Epoch 404/1000\n",
      "123/123 [==============================] - 1s 7ms/step - loss: 0.4281 - accuracy: 0.8039 - val_loss: 0.4905 - val_accuracy: 0.7647\n",
      "Epoch 405/1000\n",
      "123/123 [==============================] - 1s 7ms/step - loss: 0.4280 - accuracy: 0.8056 - val_loss: 0.4904 - val_accuracy: 0.7647\n",
      "Epoch 406/1000\n",
      "123/123 [==============================] - 1s 7ms/step - loss: 0.4279 - accuracy: 0.8039 - val_loss: 0.4902 - val_accuracy: 0.7647\n",
      "Epoch 407/1000\n",
      "123/123 [==============================] - 1s 7ms/step - loss: 0.4278 - accuracy: 0.8088 - val_loss: 0.4901 - val_accuracy: 0.7647\n",
      "Epoch 408/1000\n",
      "123/123 [==============================] - 1s 7ms/step - loss: 0.4277 - accuracy: 0.8056 - val_loss: 0.4901 - val_accuracy: 0.7647\n",
      "Epoch 409/1000\n",
      "123/123 [==============================] - 1s 7ms/step - loss: 0.4276 - accuracy: 0.8039 - val_loss: 0.4895 - val_accuracy: 0.7647\n",
      "Epoch 410/1000\n",
      "123/123 [==============================] - 1s 7ms/step - loss: 0.4275 - accuracy: 0.8039 - val_loss: 0.4897 - val_accuracy: 0.7647\n",
      "Epoch 411/1000\n",
      "123/123 [==============================] - 1s 7ms/step - loss: 0.4274 - accuracy: 0.8056 - val_loss: 0.4898 - val_accuracy: 0.7647\n",
      "Epoch 412/1000\n",
      "123/123 [==============================] - 1s 7ms/step - loss: 0.4273 - accuracy: 0.8056 - val_loss: 0.4894 - val_accuracy: 0.7647\n",
      "Epoch 413/1000\n",
      "123/123 [==============================] - 1s 7ms/step - loss: 0.4272 - accuracy: 0.8056 - val_loss: 0.4896 - val_accuracy: 0.7647\n",
      "Epoch 414/1000\n",
      "123/123 [==============================] - 1s 7ms/step - loss: 0.4271 - accuracy: 0.8056 - val_loss: 0.4895 - val_accuracy: 0.7647\n",
      "Epoch 415/1000\n",
      "123/123 [==============================] - 1s 7ms/step - loss: 0.4271 - accuracy: 0.8072 - val_loss: 0.4894 - val_accuracy: 0.7647\n",
      "Epoch 416/1000\n",
      "123/123 [==============================] - 1s 7ms/step - loss: 0.4272 - accuracy: 0.8105 - val_loss: 0.4892 - val_accuracy: 0.7647\n",
      "Epoch 417/1000\n",
      "123/123 [==============================] - 1s 7ms/step - loss: 0.4269 - accuracy: 0.8056 - val_loss: 0.4893 - val_accuracy: 0.7647\n",
      "Epoch 418/1000\n",
      "123/123 [==============================] - 1s 7ms/step - loss: 0.4269 - accuracy: 0.8039 - val_loss: 0.4889 - val_accuracy: 0.7647\n",
      "Epoch 419/1000\n",
      "123/123 [==============================] - 1s 7ms/step - loss: 0.4267 - accuracy: 0.8039 - val_loss: 0.4891 - val_accuracy: 0.7647\n",
      "Epoch 420/1000\n",
      "123/123 [==============================] - 1s 8ms/step - loss: 0.4266 - accuracy: 0.8056 - val_loss: 0.4885 - val_accuracy: 0.7647\n",
      "Epoch 421/1000\n",
      "123/123 [==============================] - 1s 7ms/step - loss: 0.4265 - accuracy: 0.8039 - val_loss: 0.4889 - val_accuracy: 0.7647\n",
      "Epoch 422/1000\n",
      "123/123 [==============================] - 1s 7ms/step - loss: 0.4266 - accuracy: 0.8088 - val_loss: 0.4890 - val_accuracy: 0.7647\n",
      "Epoch 423/1000\n",
      "123/123 [==============================] - 1s 7ms/step - loss: 0.4264 - accuracy: 0.8088 - val_loss: 0.4886 - val_accuracy: 0.7647\n",
      "Epoch 424/1000\n",
      "123/123 [==============================] - 1s 7ms/step - loss: 0.4263 - accuracy: 0.8072 - val_loss: 0.4884 - val_accuracy: 0.7647\n",
      "Epoch 425/1000\n",
      "123/123 [==============================] - 1s 7ms/step - loss: 0.4261 - accuracy: 0.8056 - val_loss: 0.4884 - val_accuracy: 0.7647\n",
      "Epoch 426/1000\n",
      "123/123 [==============================] - 1s 7ms/step - loss: 0.4261 - accuracy: 0.8056 - val_loss: 0.4884 - val_accuracy: 0.7647\n",
      "Epoch 427/1000\n",
      "123/123 [==============================] - 1s 7ms/step - loss: 0.4260 - accuracy: 0.8039 - val_loss: 0.4883 - val_accuracy: 0.7647\n",
      "Epoch 428/1000\n",
      "123/123 [==============================] - 1s 7ms/step - loss: 0.4259 - accuracy: 0.8072 - val_loss: 0.4882 - val_accuracy: 0.7647\n",
      "Epoch 429/1000\n",
      "123/123 [==============================] - 1s 7ms/step - loss: 0.4261 - accuracy: 0.8072 - val_loss: 0.4881 - val_accuracy: 0.7647\n",
      "Epoch 430/1000\n",
      "123/123 [==============================] - 1s 7ms/step - loss: 0.4257 - accuracy: 0.8072 - val_loss: 0.4880 - val_accuracy: 0.7647\n",
      "Epoch 431/1000\n",
      "123/123 [==============================] - 1s 7ms/step - loss: 0.4257 - accuracy: 0.8072 - val_loss: 0.4883 - val_accuracy: 0.7647\n",
      "Epoch 432/1000\n",
      "123/123 [==============================] - 1s 7ms/step - loss: 0.4255 - accuracy: 0.8056 - val_loss: 0.4881 - val_accuracy: 0.7647\n",
      "Epoch 433/1000\n",
      "123/123 [==============================] - 1s 7ms/step - loss: 0.4257 - accuracy: 0.8072 - val_loss: 0.4881 - val_accuracy: 0.7647\n",
      "Epoch 434/1000\n",
      "123/123 [==============================] - 1s 7ms/step - loss: 0.4254 - accuracy: 0.8072 - val_loss: 0.4881 - val_accuracy: 0.7647\n",
      "Epoch 435/1000\n",
      "123/123 [==============================] - 1s 7ms/step - loss: 0.4252 - accuracy: 0.8056 - val_loss: 0.4878 - val_accuracy: 0.7647\n",
      "Epoch 436/1000\n",
      "123/123 [==============================] - 1s 7ms/step - loss: 0.4252 - accuracy: 0.8056 - val_loss: 0.4870 - val_accuracy: 0.7647\n",
      "Epoch 437/1000\n",
      "123/123 [==============================] - 1s 7ms/step - loss: 0.4250 - accuracy: 0.8105 - val_loss: 0.4877 - val_accuracy: 0.7647\n",
      "Epoch 438/1000\n",
      "123/123 [==============================] - 1s 8ms/step - loss: 0.4251 - accuracy: 0.8072 - val_loss: 0.4876 - val_accuracy: 0.7647\n",
      "Epoch 439/1000\n",
      "123/123 [==============================] - 1s 7ms/step - loss: 0.4251 - accuracy: 0.8088 - val_loss: 0.4876 - val_accuracy: 0.7647\n",
      "Epoch 440/1000\n",
      "123/123 [==============================] - 1s 8ms/step - loss: 0.4249 - accuracy: 0.8056 - val_loss: 0.4875 - val_accuracy: 0.7647\n",
      "Epoch 441/1000\n",
      "123/123 [==============================] - 1s 7ms/step - loss: 0.4247 - accuracy: 0.8088 - val_loss: 0.4873 - val_accuracy: 0.7647\n"
     ]
    }
   ],
   "source": [
    "early_stopping = tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=5)\n",
    "\n",
    "hist = model.fit(npFeatures_train,\n",
    "                 npTargets_train,\n",
    "                 validation_split=0.1,\n",
    "                 batch_size=5,\n",
    "                 epochs=1000,\n",
    "                 callbacks=[early_stopping])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "918743d5-d8c7-4a0b-8378-55172b63d9db",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def plot_performance(type_):\n",
    "    plt.plot(hist.history[f'val_{type_}'], color='red', label='Validation')\n",
    "    plt.plot(hist.history[f'{type_}'], color='blue', label='Train')\n",
    "    plt.ylim(0, 1)\n",
    "    plt.title(f'{type_}'.title())\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "b58e2009-644e-4b22-a410-0e6165e7ec4d",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_performance('loss')\n",
    "plot_performance('accuracy')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2906655-6637-43fc-9aaa-20f312c08fee",
   "metadata": {},
   "source": [
    "### 4. Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "id": "d4d5dc12-349b-4bb8-933a-1b4704d6ce1b",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14/14 [==============================] - 0s 8ms/step\n"
     ]
    }
   ],
   "source": [
    "predictions = model.predict(npTest_data)\n",
    "threshold = 0.5\n",
    "binary_predictions = [1 if p > threshold else 0 for p in predictions]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "id": "d7ea3afd-d59e-4e21-81be-0cdca565cec3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df_predictions = pd.DataFrame({\n",
    "    'PassengerId': test_data_passengers_id,\n",
    "    'Survived': binary_predictions})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9139c0ac-6780-4939-9d4d-05d6b402e07d",
   "metadata": {
    "tags": []
   },
   "source": [
    "### 4.Saving predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "id": "c77276e5-ac49-42bd-b558-1e8b9ed1a539",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df_predictions.to_csv('predictions/prediction2.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e42223d7-33a3-447d-8eef-4b4d75fa4734",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf_gpu_py39",
   "language": "python",
   "name": "tf_gpu_py39"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
